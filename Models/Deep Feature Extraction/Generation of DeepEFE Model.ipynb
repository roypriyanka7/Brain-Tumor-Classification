{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2319f89a",
   "metadata": {},
   "source": [
    "### Import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5bd4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from skimage import color\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d43d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "from PIL import Image\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059f12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install visualkeras\n",
    "import tensorflow as tf\n",
    "import visualkeras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection   import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe42b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # General parameters\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b5412a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "folder_path = \"ds_two\"             # base/root directory\n",
    "\n",
    "no_tumor = os.listdir(folder_path + '/no_tumor/')\n",
    "glioma = os.listdir(folder_path + '/glioma/')\n",
    "meningioma = os.listdir(folder_path + '/meningioma/')\n",
    "pituitary = os.listdir(folder_path + '/pituitary/')\n",
    "craniopharyngioma = os.listdir(folder_path + '/craniopharyngioma_final_1070/')\n",
    "\n",
    "# no_tumor, glioma, meningioma, pituitary, craniopharyngioma\n",
    "\n",
    "dataset=[]\n",
    "lab=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a778703",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in no_tumor:\n",
    "    image=cv2.imread(folder_path + '/no_tumor/' + image_name)\n",
    "    image=Image.fromarray(image,'RGB')\n",
    "    image=image.resize((240,240))\n",
    "    dataset.append(np.array(image))\n",
    "    lab.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c175b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in glioma:\n",
    "    image=cv2.imread(folder_path + '/glioma/' + image_name)\n",
    "    image=Image.fromarray(image,'RGB')\n",
    "    image=image.resize((240,240))\n",
    "    dataset.append(np.array(image))\n",
    "    lab.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e9f385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in meningioma:\n",
    "    image=cv2.imread(folder_path + '/meningioma/' + image_name)\n",
    "    image=Image.fromarray(image,'RGB')\n",
    "    image=image.resize((240,240))\n",
    "    dataset.append(np.array(image))\n",
    "    lab.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bc6c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in pituitary:\n",
    "    image=cv2.imread(folder_path + '/pituitary/' + image_name)\n",
    "    image=Image.fromarray(image,'RGB')\n",
    "    image=image.resize((240,240))\n",
    "    dataset.append(np.array(image))\n",
    "    lab.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe8efcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in craniopharyngioma:\n",
    "    image=cv2.imread(folder_path + '/craniopharyngioma_final_1070/' + image_name)\n",
    "    image=Image.fromarray(image,'RGB')\n",
    "    image=image.resize((240,240))\n",
    "    dataset.append(np.array(image))\n",
    "    lab.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8610f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8103, 240, 240, 3) (8103,)\n"
     ]
    }
   ],
   "source": [
    "dataset = np.array(dataset)\n",
    "lab = np.array(lab)\n",
    "print(dataset.shape, lab.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8a7fac",
   "metadata": {},
   "source": [
    "### Deep Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c2fca",
   "metadata": {},
   "source": [
    "##### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62b3b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "base_model = tf.keras.applications.vgg16.VGG16(include_top =False,weights='imagenet')\n",
    "base_model.trainable = False\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "input = Input(shape=(240,240,3))\n",
    "x = Rescaling(scale =1./127.5)(input)\n",
    "x = base_model(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(units = 4096,activation='relu')(x)\n",
    "x = Dense(units = 1000,activation = 'relu')(x)\n",
    "output = Dense(5,activation = 'sigmoid')(x)\n",
    "model = tf.keras.Model(input,output)\n",
    "\n",
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c442892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8103 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(rescale=1./127.5)\n",
    "\n",
    "subdirectories = ['no_tumor', 'glioma', 'meningioma', 'pituitary', 'craniopharyngioma_final_1070']\n",
    "\n",
    "# Create a generator for the images in the subdirectories\n",
    "generator = datagen.flow_from_directory(\n",
    "    folder_path,\n",
    "    target_size=(240,240),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "#     class_mode=None,\n",
    "    shuffle=False,\n",
    "    classes=subdirectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8f1c300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 419s 2s/step\n"
     ]
    }
   ],
   "source": [
    "vgg_features = model.predict(generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2516f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8103\n"
     ]
    }
   ],
   "source": [
    "print(len(vgg_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c611ac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted deep features: 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of extracted deep features:\", vgg_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1809cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('extracted_features_vgg.npy', vgg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9c64b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8103, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a131f03-be2a-4e4f-9eac-b44c3c7fe771",
   "metadata": {},
   "source": [
    "##### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8956698c-feb3-4d70-afc0-51698f07a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet201\n",
    "\n",
    "model = DenseNet201(weights='imagenet', include_top=False, input_shape=(240, 240, 3))\n",
    "\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "\n",
    "dataset = preprocess_input(np.array(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27d048a5-db68-46df-8f79-7755d017a35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8103 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "subdirectories = ['no_tumor', 'glioma', 'meningioma', 'pituitary', 'craniopharyngioma_final_1070']\n",
    "\n",
    "# Create a generator for the images in the subdirectories\n",
    "generator = datagen.flow_from_directory(\n",
    "    folder_path,\n",
    "    target_size=(240,240),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "#     class_mode=None,\n",
    "    shuffle=False,\n",
    "    classes=subdirectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aac10ca2-7cff-45a7-869d-922405513e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 409s 2s/step\n"
     ]
    }
   ],
   "source": [
    "dense_features = model.predict(generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90ab73c4-ea91-4c78-8f4c-71ea27287674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8103\n"
     ]
    }
   ],
   "source": [
    "print(len(dense_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c872b207-760f-445d-8b98-c526d8f879d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted deep features: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of extracted deep features:\", dense_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a77be45a-ee30-478a-a4a3-c820c9adb930",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('extracted_features_dense.npy', dense_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e76bf3b-8d23-456d-9ca1-8aeb86b05c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8103, 7, 7, 1920)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12d79aa7-a265-41c3-9d87-cd821a2d28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features into a 2D array\n",
    "num_samples = dense_features.shape[0]\n",
    "reshaped_dense = dense_features.reshape(num_samples, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b130a1cc-6a2b-4dcb-9d5a-bcb4999f37bc",
   "metadata": {},
   "source": [
    "##### InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4278cb06-47ef-4d70-b26f-1f7116381357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "\n",
    "model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(240, 240, 3))\n",
    "\n",
    "dataset = preprocess_input(np.array(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87f76a17-804c-474c-a09e-65538eb267ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8103 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "subdirectories = ['no_tumor', 'glioma', 'meningioma', 'pituitary', 'craniopharyngioma_final_1070']\n",
    "\n",
    "# Create a generator for the images in the subdirectories\n",
    "generator = datagen.flow_from_directory(\n",
    "    folder_path,\n",
    "    target_size=(240,240),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "#     class_mode=None,\n",
    "    shuffle=False,\n",
    "    classes=subdirectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d245a78a-8df9-4a85-9b53-175977efcd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 298s 1s/step\n"
     ]
    }
   ],
   "source": [
    "inceptionResNet_features = model.predict(generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc96f125-1a07-499c-946b-501678fd84aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8103\n"
     ]
    }
   ],
   "source": [
    "print(len(inceptionResNet_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a57c8361-9cb4-4fe7-9001-206b8eea31f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of extracted deep features: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of extracted deep features:\", inceptionResNet_features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8545b4b3-9420-409c-8206-2d3964ffd815",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('inceptionResNet_features.npy', inceptionResNet_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c093dee-f156-4e09-9620-a6e37b9e0473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8103, 6, 6, 1536)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inceptionResNet_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0986e1d-9653-4fda-8921-cb87c82714bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features into a 2D array\n",
    "num_samples = inceptionResNet_features.shape[0]\n",
    "reshaped_inceptionResNet = inceptionResNet_features.reshape(num_samples, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee6664-d606-42c4-ae2d-3d836db38ca2",
   "metadata": {},
   "source": [
    "### Concatanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8017b89-9515-4d9d-b190-d6646a047a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "from keras.layers import Concatenate, Input, Flatten, Dense\n",
    "\n",
    "input_layer = Input(shape=(240, 240, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0d609ff-4423-42a0-bf05-c52700dadd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the extracted features\n",
    "concatenated_features = Concatenate()([reshaped_dense, vgg_features, reshaped_inceptionResNet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e546765c-fbbb-43d7-b94c-c8dacada36e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8103\n"
     ]
    }
   ],
   "source": [
    "print(len(concatenated_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb7f5b9e-c250-4ed1-a3b5-90054d6abf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149381\n"
     ]
    }
   ],
   "source": [
    "print(len(concatenated_features[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final features as 'concatenated_features' for future use\n",
    "np.save(\"concatenated_features.npy\", concatenated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a9a1ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "# Flatten the features to use them for classification\n",
    "features_flatten = np.reshape(concatenated_features, (concatenated_features.shape[0], -1))\n",
    "\n",
    "# Define the labels for the images in the subdirectories\n",
    "labels = generator.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d00e41-efea-4d31-b2a7-76a001cfa0d5",
   "metadata": {},
   "source": [
    "Apply the classification models afterwards. The model will generate results for the balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf2c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3582f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
